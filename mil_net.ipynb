{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mil_net.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPiu0FUpDXOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q12ET7dhDjBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seg = 5\n",
        "max_word = 100\n",
        "\n",
        "train_amount = 5000\n",
        "test_amount = 1000\n",
        "\n",
        "w2v_len = 30\n",
        "level_class_cnt = 5\n",
        "\n",
        "dropout_rate = 0.5\n",
        "hidden_feature_dim = 70\n",
        "gru_feature_dim = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDDd0ZLhESr2",
        "colab_type": "code",
        "outputId": "8d8c5860-2699-4c62-c61f-f425bac94e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x_train = np.random.randint(0, 100, (train_amount, max_seg, max_word))\n",
        "x_test = np.random.randint(0, 100, (test_amount, max_seg, max_word))\n",
        "\n",
        "y_train = np.random.randint(0, 5, (train_amount))\n",
        "y_test = np.random.randint(0, 5, (test_amount))\n",
        "\n",
        "fake_w2v = np.random.rand(100, w2v_len)\n",
        "\n",
        "x_train = np.expand_dims(fake_w2v[x_train], axis=-1)\n",
        "x_test = np.expand_dims(fake_w2v[x_test], axis=-1)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 5, 100, 30, 1) (5000,)\n",
            "(1000, 5, 100, 30, 1) (1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCbWOTVnM6QX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' A CNN unit to encode segment with single kernel height.\n",
        "\n",
        "The unit would apply a convolution to its input to get a 2-dimensional \n",
        "tensor, then apply max overtime pooling to get a single dimensional tensor.\n",
        "\n",
        "Shape_In: (batch_size, seg_max, word_max, vec_len, 1)\n",
        "Shape_Out: (batch_size, 1, hidden_feature_dim, 1)\n",
        "\n",
        "Args:\n",
        "    input_shape ((int, int)): The shape of segment matrix. (word_max * vec_len)\n",
        "    kernel_height (int): The height of the convolution kernel.\n",
        "    index (int): The index of the segment in its belonging document.\n",
        "\n",
        "Returns:\n",
        "    (Model): The CNN model to encode the segment matrix.\n",
        "'''\n",
        "def __get_sentence_encode_unit(input_shape, kernel_height, index):\n",
        "    cnned_height = input_shape[0] - kernel_height + 1\n",
        "    def doc_filter(tensor_in, index):\n",
        "        begin, size = [0, index, 0, 0, 0], [-1, 1, -1, -1, -1]\n",
        "        return tf.squeeze(tf.slice(tensor_in, begin, size), axis=1)\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Lambda(doc_filter, arguments={'index':index}),\n",
        "        tf.keras.layers.Conv2D(hidden_feature_dim, (kernel_height, input_shape[1])),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.ReLU(),\n",
        "        tf.keras.layers.Reshape((cnned_height, hidden_feature_dim, 1)),\n",
        "        tf.keras.layers.MaxPool2D((cnned_height, 1))\n",
        "    ])\n",
        "\n",
        "\n",
        "''' A CNN unit to encode segment with multiple kernel heights\n",
        "\n",
        "The unit would apply operation defined in `__get_sentence_encode_unit` for \n",
        "different kernel heights, then concat the result as a 1-dimensional tensor.\n",
        "\n",
        "Shape_In: (batch_size, seg_max, word_max, vec_len, 1)\n",
        "Shape_Out: (batch_size, hidden_feature_dim * len(kernel_heights))\n",
        "\n",
        "Args:\n",
        "    input_shape ((int, int, int)): The shape of the document. (seg_max * word_max * vec_len)\n",
        "    kernel_heights ([int]): The list of the kernel heights.\n",
        "    index: The index of the segment in its belonging document.\n",
        "\n",
        "Returns:\n",
        "    (Model): The CNN model to encode the segment matrix.\n",
        "'''\n",
        "def __get_multi_kernel_encode_unit(input_shape, kernel_heights, index):\n",
        "    model_input = tf.keras.Input((*input_shape, 1))\n",
        "    cnn_layers = [__get_sentence_encode_unit(input_shape[1:], h, index)\n",
        "                     (model_input) for h in kernel_heights]\n",
        "    concated_layers = tf.keras.layers.concatenate(cnn_layers)\n",
        "    model_output = tf.keras.layers.Flatten()(concated_layers)\n",
        "    return tf.keras.Model(model_input, model_output)\n",
        "\n",
        "\n",
        "''' The softmax linear classifier for predicting segment sentiment.\n",
        "\n",
        "Shape_In: (batch_size, hidden_feature_dim * len(kernel_heights))\n",
        "Shape_Out: (batch_size, level_class_cnt)\n",
        "\n",
        "Args:\n",
        "    index (int): The index of the segment in its belonging document.\n",
        "\n",
        "Returns:\n",
        "    (Model): The softmax linear classifier to predict segment sentiment.\n",
        "'''\n",
        "def __get_seg_classifier_unit(index):\n",
        "    def doc_filter(tensor_in, index):\n",
        "        begin, size = [0, index, 0], [-1, 1, -1]\n",
        "        return tf.squeeze(tf.slice(tensor_in, begin, size), axis=1)\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Lambda(doc_filter, arguments={'index':index}),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Dense(level_class_cnt, activation='softmax')\n",
        "    ])\n",
        "\n",
        "\n",
        "''' The unit to get the attention weight for a segment from hidden feature.\n",
        "\n",
        "Shape_In: (batch_size, seg_max, gru_feature_dim * 2)\n",
        "Shape_Out: (batch_size, 1)\n",
        "\n",
        "Args:\n",
        "    index (int): The index of the segment in its belonging document.\n",
        "\n",
        "Returns:\n",
        "    (Model): The model for predicting attention weight for a segment.\n",
        "\n",
        "'''\n",
        "def __get_attention_unit(index):\n",
        "    def doc_filter(tensor_in, index):\n",
        "        begin, size = [0, index, 0], [-1, 1, -1]\n",
        "        return tf.squeeze(tf.slice(tensor_in, begin, size), axis=1)\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Lambda(doc_filter, arguments={'index':index}),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Dense(2 * gru_feature_dim, activation='tanh'),\n",
        "        tf.keras.layers.Dense(1, use_bias=False, activation='softmax')\n",
        "    ])\n",
        "\n",
        "\n",
        "''' A bidirectional-GRU unit to extract the hidden vectors.\n",
        "\n",
        "The hidden vectors are used to predict the attention weights of the model.\n",
        "\n",
        "Shape_In: (batch_size, seg_max, hidden_feature_dim * len(kernel_heights))\n",
        "Shape_Out: (batch_size, seg_max, gru_feature_dim * 2)\n",
        "\n",
        "Returns:\n",
        "    (Model): The bidirectional-GRU unit to predict the hidden vectors.\n",
        "'''\n",
        "def __get_bidirectional_gru_unit():\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.GRU(gru_feature_dim, return_sequences=True)\n",
        "        )\n",
        "    ])\n",
        "\n",
        "\n",
        "''' A CNN module to encode segment with multiple kernel heights.\n",
        "\n",
        "The module would create feature matrices for a document.\n",
        "\n",
        "Shape_In: (batch_size, seg_max, word_max, vec_len, 1)\n",
        "Shape_Out: (batch_size, seg_max, hidden_feature_dim * len(kernel_heights))\n",
        "\n",
        "Args:\n",
        "    input_size ((int, int)): The size of the input. (seg_max * word_max * vec_len)\n",
        "    kernel_heights ([int]): The list of the kernel heights.\n",
        "\n",
        "Returns:\n",
        "    (Model): The CNN model to encode the segment matrix.\n",
        "'''\n",
        "def get_sentence_encode_module(input_shape, kernel_heights):\n",
        "    model_input = tf.keras.Input((*input_shape, 1))\n",
        "    encoder_layers = [__get_multi_kernel_encode_unit(input_shape, \n",
        "                                                     kernel_heights, i)\n",
        "                      (model_input) for i in range(input_shape[0])]\n",
        "    concated_layers = tf.keras.layers.Concatenate()(encoder_layers)\n",
        "    new_shape = (input_shape[0], hidden_feature_dim * len(kernel_heights))\n",
        "    model_output = tf.keras.layers.Reshape(new_shape)(concated_layers)\n",
        "    return tf.keras.Model(model_input, model_output)\n",
        "\n",
        "\n",
        "''' The softmax linear classifier for predicting segment sentiment in document.\n",
        "\n",
        "Shape_In: (batch_size, seg_max, hidden_feature_dim * len(kernel_heights))\n",
        "Shape_Out: (batch_size, seg_max, level_class_cnt)\n",
        "\n",
        "Args:\n",
        "    input_shape ((int, int)): The shape of the document. (seg_max * \n",
        "        (hidden_feature_dim * len(kernel_heights)))\n",
        "\n",
        "Returns:\n",
        "    (Model): The sentiment classifier for all documents.\n",
        "'''\n",
        "def get_seg_classifier_module(input_shape):\n",
        "    model_input = tf.keras.Input(input_shape)\n",
        "    softmax_layers = [__get_seg_classifier_unit(i)(model_input) \n",
        "                      for i in range(input_shape[0])]\n",
        "    concated_layers = tf.keras.layers.Concatenate()(softmax_layers)\n",
        "    new_shape = (input_shape[0], level_class_cnt)\n",
        "    model_output = tf.keras.layers.Reshape(new_shape)(concated_layers)\n",
        "    return tf.keras.Model(model_input, model_output)\n",
        "\n",
        "\n",
        "''' The attentioal model for predicting the attention weights for each segment.\n",
        "\n",
        "Shape_In: (batch_size, seg_max, hidden_feature_dim * len(kernel_heights))\n",
        "Shape_Out: (batch_size, seg_max, 1)\n",
        "\n",
        "Args:\n",
        "    input_shape ((int, int)): The shape of the document. (seg_max * \n",
        "        (hidden_feature_dim * len(kernel_heights)))\n",
        "\n",
        "Returns:\n",
        "    (Model): The model for predicting attention weights.\n",
        "'''\n",
        "def get_attention_module(input_shape):\n",
        "    model_input = tf.keras.Input(input_shape)\n",
        "    biglu_layer = __get_bidirectional_gru_unit()(model_input)\n",
        "    weight_layers = [__get_attention_unit(i)(biglu_layer) \n",
        "                     for i in range(input_shape[0])]\n",
        "    concated_layers = tf.keras.layers.Concatenate()(weight_layers)\n",
        "    new_shape = (input_shape[0], 1)\n",
        "    model_output = tf.keras.layers.Reshape(new_shape)(concated_layers)\n",
        "    return tf.keras.Model(model_input, model_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be9L2dRmz37F",
        "colab_type": "code",
        "outputId": "94a428a8-bcf6-47aa-8e3d-d93d5dfbb774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "model_input = tf.keras.Input((5, 100, 30, 1))\n",
        "encoding_model = get_sentence_encode_module((5, 100, 30), [3, 4, 5])(model_input)\n",
        "\n",
        "attention_model = get_attention_module((5, 210))(encoding_model)\n",
        "classification_model = get_seg_classifier_module((5, 210))(encoding_model)\n",
        "\n",
        "matmul_layer = tf.keras.layers.Lambda(tf.matmul, arguments={'transpose_a': True, 'b': attention_model})(classification_model)\n",
        "squeeze_layer = tf.keras.layers.Lambda(tf.squeeze, arguments={'axis': -1})(matmul_layer)\n",
        "\n",
        "model = tf.keras.Model(model_input, squeeze_layer)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Model Compiled.')\n",
        "\n",
        "model.fit(x_train, y_train, epochs=1)\n",
        "\n",
        "model.predict(x_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Compiled.\n",
            "5000/5000 [==============================] - 13s 3ms/sample - loss: 1.6674 - acc: 0.1430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9766311 , 1.0833453 , 0.8760857 , 1.0538265 , 1.0101113 ],\n",
              "       [1.0264621 , 1.084794  , 0.86409116, 1.0326786 , 0.9919741 ],\n",
              "       [0.994607  , 1.0902966 , 0.86998445, 1.0479234 , 0.99718827],\n",
              "       ...,\n",
              "       [0.98818886, 1.1085814 , 0.8810852 , 1.0568564 , 0.9652882 ],\n",
              "       [0.9786608 , 1.0765887 , 0.8596323 , 1.0734288 , 1.0116892 ],\n",
              "       [1.0153153 , 1.0630189 , 0.85709107, 1.0715418 , 0.9930332 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMi3XPOBUWBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}