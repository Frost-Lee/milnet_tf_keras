{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mil_net.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPiu0FUpDXOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q12ET7dhDjBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seg = 5\n",
        "max_word = 100\n",
        "\n",
        "train_amount = 5000\n",
        "test_amount = 1000\n",
        "\n",
        "w2v_len = 30\n",
        "level_class_cnt = 5\n",
        "\n",
        "dropout_rate = 0.5\n",
        "hidden_feature_dim = 70\n",
        "gru_feature_dim = 150\n",
        "kernel_heights = [3, 4, 5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDDd0ZLhESr2",
        "colab_type": "code",
        "outputId": "594691cc-e82f-4f3a-942a-a6dd4acd424d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x_train = np.random.randint(0, 100, (train_amount, max_seg, max_word))\n",
        "x_test = np.random.randint(0, 100, (test_amount, max_seg, max_word))\n",
        "\n",
        "y_train = np.random.randint(0, 5, (train_amount))\n",
        "y_test = np.random.randint(0, 5, (test_amount))\n",
        "\n",
        "fake_w2v = np.random.rand(100, w2v_len)\n",
        "\n",
        "x_train = np.expand_dims(fake_w2v[x_train], axis=-1)\n",
        "x_test = np.expand_dims(fake_w2v[x_test], axis=-1)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 5, 100, 30, 1) (5000,)\n",
            "(1000, 5, 100, 30, 1) (1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCbWOTVnM6QX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' Slice a piece from one dimension.\n",
        "\n",
        "The layer would slice the `index`th dimension from `target_dim` dimension of\n",
        "the input tensor, which have `total_dim` dimensions, then squeeze the tensor\n",
        "over the sliced dimension.\n",
        "\n",
        "Args:\n",
        "    total_dim (int): The total number of dimensions of the input tensor.\n",
        "    target_dim (int): The index of the dimension that need to slice.\n",
        "    index (int): The index of the dimension to keep in the slicing operation.\n",
        "\n",
        "Returns:\n",
        "    (Layer): A keras layer that implement the operation.\n",
        "'''\n",
        "def __get_filter_layer(total_dim, target_dim, index):\n",
        "    def tensor_filter(tensor_in):\n",
        "        nonlocal index\n",
        "        begin = [0 if i != target_dim else index for i in range(total_dim)]\n",
        "        size = [-1 if i != target_dim else 1 for i in range(total_dim)]\n",
        "        return tf.squeeze(tf.slice(tensor_in, begin, size), axis=target_dim)\n",
        "    return tf.keras.layers.Lambda(tensor_filter)\n",
        "\n",
        "\n",
        "''' Implement `submodel` for each slice of tensor.\n",
        "\n",
        "The model would slice its input tensor into pieces using `__get_filter_layer` \n",
        "along `branch_index`th dimension, then for each slice, implement submodel, \n",
        "finally the outputs of different submodels would be concated and reshaped to \n",
        "meet the demand of output.\n",
        "\n",
        "Args:\n",
        "    input_shape tuple(int): The shape of the input tensor.\n",
        "    branch_index (int): The index of the dimension to slice, start from 0 as \n",
        "        sample amount dimension.\n",
        "    output_shape tuple(int): The shape of the output tensor.\n",
        "    submodel (Model): The model to apply to different slices.\n",
        "    args (dict): The argument dictionary for `submodel`, exclude the `index` \n",
        "        argument.\n",
        "'''\n",
        "def __get_branch_model(input_shape, branch_index, output_shape, submodel, args={}):\n",
        "    model_input = tf.keras.Input(input_shape)\n",
        "    branch_models = [submodel(**dict(args, **{'index': i}))(model_input) \n",
        "                     for i in range(input_shape[branch_index - 1])]\n",
        "    concated_layers = tf.keras.layers.Concatenate()(branch_models)\n",
        "    model_output = tf.keras.layers.Reshape(output_shape)(concated_layers)\n",
        "    return tf.keras.Model(model_input, model_output)\n",
        "\n",
        "\n",
        "''' A CNN unit to encode segment with single kernel height.\n",
        "\n",
        "The unit would apply a convolution to its input to get a 2-dimensional \n",
        "tensor, then apply max overtime pooling to get a single dimensional tensor.\n",
        "\n",
        "Args:\n",
        "    input_shape ((int, int)): The shape of segment matrix. (word_max, vec_len)\n",
        "    kernel_height (int): The height of the convolution kernel.\n",
        "    index (int): The index of the segment in its belonging document.\n",
        "\n",
        "Returns:\n",
        "    (Model): The CNN model to encode the segment matrix.\n",
        "'''\n",
        "def __get_sentence_encode_unit(input_shape, kernel_height, index):\n",
        "    cnned_height = input_shape[0] - kernel_height + 1\n",
        "    return tf.keras.models.Sequential([\n",
        "        __get_filter_layer(5, 1, index),\n",
        "        tf.keras.layers.Conv2D(hidden_feature_dim, (kernel_height, input_shape[1])),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.ReLU(),\n",
        "        tf.keras.layers.Reshape((cnned_height, hidden_feature_dim, 1)),\n",
        "        tf.keras.layers.MaxPool2D((cnned_height, 1))\n",
        "    ])\n",
        "\n",
        "\n",
        "''' A CNN unit to encode segment with multiple kernel heights\n",
        "\n",
        "The unit would apply operation defined in `__get_sentence_encode_unit` for \n",
        "different kernel heights, then concat the result as a 1-dimensional tensor.\n",
        "\n",
        "Args:\n",
        "    input_shape ((int, int, int)): The shape of the document. (seg_max, word_max, vec_len)\n",
        "    kernel_heights ([int]): The list of the kernel heights.\n",
        "    index: The index of the segment in its belonging document.\n",
        "\n",
        "Returns:\n",
        "    (Model): The CNN model to encode the segment matrix.\n",
        "'''\n",
        "def __get_multi_kernel_encode_unit(input_shape, kernel_heights, index):\n",
        "    model_input = tf.keras.Input((*input_shape, 1))\n",
        "    cnn_layers = [__get_sentence_encode_unit(input_shape[1:], h, index)\n",
        "                     (model_input) for h in kernel_heights]\n",
        "    concated_layers = tf.keras.layers.concatenate(cnn_layers)\n",
        "    model_output = tf.keras.layers.Flatten()(concated_layers)\n",
        "    return tf.keras.Model(model_input, model_output)\n",
        "\n",
        "\n",
        "''' The softmax linear classifier for predicting segment sentiment.\n",
        "\n",
        "Args:\n",
        "    index (int): The index of the segment in its belonging document.\n",
        "\n",
        "Returns:\n",
        "    (Model): The softmax linear classifier to predict segment sentiment.\n",
        "'''\n",
        "def __get_seg_classifier_unit(index):\n",
        "    return tf.keras.models.Sequential([\n",
        "        __get_filter_layer(3, 1, index),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Dense(level_class_cnt, activation='softmax')\n",
        "    ])\n",
        "\n",
        "\n",
        "''' The unit to get the attention weight for a segment from hidden feature.\n",
        "\n",
        "Args:\n",
        "    index (int): The index of the segment in its belonging document.\n",
        "\n",
        "Returns:\n",
        "    (Model): The model for predicting attention weight for a segment.\n",
        "\n",
        "'''\n",
        "def __get_attention_unit(index):\n",
        "    return tf.keras.models.Sequential([\n",
        "        __get_filter_layer(3, 1, index),\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Dense(2 * gru_feature_dim, activation='tanh'),\n",
        "        tf.keras.layers.Dense(1, use_bias=False, activation='softmax')\n",
        "    ])\n",
        "\n",
        "\n",
        "''' A bidirectional-GRU unit to extract the hidden vectors.\n",
        "\n",
        "The hidden vectors are used to predict the attention weights of the model.\n",
        "\n",
        "Returns:\n",
        "    (Model): The bidirectional-GRU unit to predict the hidden vectors.\n",
        "'''\n",
        "def __get_bidirectional_gru_unit():\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.GRU(gru_feature_dim, return_sequences=True)\n",
        "        )\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be9L2dRmz37F",
        "colab_type": "code",
        "outputId": "796289b0-38ef-4927-d675-9442d447eeb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model_input = tf.keras.Input((max_seg, max_word, w2v_len, 1))\n",
        "\n",
        "encoding_model = __get_branch_model(\n",
        "    input_shape=(max_seg, max_word, w2v_len, 1), \n",
        "    branch_index=1, \n",
        "    output_shape=(max_seg, len(kernel_heights) * hidden_feature_dim), \n",
        "    submodel=__get_multi_kernel_encode_unit, \n",
        "    args={'kernel_heights': kernel_heights, 'input_shape': (max_seg, max_word, w2v_len)}\n",
        ")(model_input)\n",
        "\n",
        "biglu_model = __get_bidirectional_gru_unit()(encoding_model)\n",
        "\n",
        "attention_model = __get_branch_model(\n",
        "    input_shape=(max_seg, 2 * gru_feature_dim), \n",
        "    branch_index=1, \n",
        "    output_shape=(max_seg, 1), \n",
        "    submodel=__get_attention_unit\n",
        ")(biglu_model)\n",
        "\n",
        "classification_model = __get_branch_model(\n",
        "    input_shape=(max_seg, len(kernel_heights) * hidden_feature_dim), \n",
        "    branch_index=1, \n",
        "    output_shape=(max_seg, level_class_cnt), \n",
        "    submodel=__get_seg_classifier_unit\n",
        ")(encoding_model)\n",
        "\n",
        "weighted_layer = tf.keras.layers.Lambda(tf.matmul, \n",
        "                                        arguments={'transpose_a': True, 'b': attention_model})(classification_model)\n",
        "\n",
        "squeeze_layer = tf.keras.layers.Lambda(tf.squeeze, arguments={'axis': -1})(weighted_layer)\n",
        "\n",
        "model = tf.keras.Model(model_input, squeeze_layer)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Model Compiled.')\n",
        "\n",
        "model.fit(x_train, y_train, epochs=1)\n",
        "\n",
        "print(model.predict(x_test).shape)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Compiled.\n",
            "5000/5000 [==============================] - 11s 2ms/sample - loss: 1.7365 - acc: 0.0920\n",
            "(1000, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EciimziuXbUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}