{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mil_net.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPiu0FUpDXOg",
        "colab_type": "code",
        "outputId": "a86deb26-815b-4cba-934b-b16404ac2c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import h5py\n",
        "from random import shuffle\n",
        "from functools import reduce\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "# !pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q12ET7dhDjBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seg = 12\n",
        "max_word = 34\n",
        "level_class_cnt = 5\n",
        "test_percentage = 0.2\n",
        "\n",
        "dropout_rate = 0.5\n",
        "eta = 1e-4\n",
        "hidden_feature_dim = 100\n",
        "attention_key_dim = 100\n",
        "gru_feature_dim = 50\n",
        "kernel_heights = [3, 4, 5]\n",
        "\n",
        "batch_size = 256\n",
        "epochs = 25\n",
        "\n",
        "input_path = '/content/gdrive/My Drive/data_source/milnet/sentence_level/electronics.hdf5'\n",
        "w2v_weights_path = '/content/gdrive/My Drive/data_source/milnet/sentence_level/weights.npy'\n",
        "# tensorboard_log_dir = '/Users/Frost/Desktop/log/'\n",
        "\n",
        "model_out_path = '/content/gdrive/My Drive/data_source/milnet/results/model_stop_w2v_35_11_edu.h5'\n",
        "\n",
        "sample_amount = 0\n",
        "mini_batch_cnt = 0\n",
        "with h5py.File(input_path) as in_file:\n",
        "    for index in range(len(in_file['label/'].keys())):\n",
        "        mini_batch_cnt += 1\n",
        "        sample_amount += len(in_file['label/' + str(index)])\n",
        "batch_indices = [*range(mini_batch_cnt)]\n",
        "shuffle(batch_indices)\n",
        "train_batches = batch_indices[0:int(mini_batch_cnt * (1 - test_percentage))]\n",
        "test_batches = batch_indices[int(mini_batch_cnt * (1 - test_percentage)):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDDd0ZLhESr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v = np.load(w2v_weights_path, allow_pickle=True)\n",
        "w2v_len = w2v.shape[1]\n",
        "\n",
        "def label_map(raw_label):\n",
        "    return raw_label\n",
        "#     if raw_label < 2:\n",
        "#         return 0\n",
        "#     elif raw_label < 3:\n",
        "#         return 1\n",
        "#     else:\n",
        "#         return 2\n",
        "\n",
        "def data_generator(batch_indices, epochs=epochs):\n",
        "    global batch_size, input_path\n",
        "    with h5py.File(input_path) as in_file:\n",
        "        feature_array, label_array = np.zeros((batch_size, max_seg, max_word)), np.zeros((batch_size, 1))\n",
        "        batch_index = 0\n",
        "        for _ in range(epochs):\n",
        "            shuffle(batch_indices)\n",
        "            for index in batch_indices:\n",
        "                doc, label = in_file['document/' + str(index)], in_file['label/' + str(index)]\n",
        "                random_doc_order = [*range(len(doc))]\n",
        "                shuffle(random_doc_order)\n",
        "                for i in random_doc_order:\n",
        "                    feature_array[batch_index] = np.array([doc[i].astype('float64')])\n",
        "                    label_array[batch_index] = label_map(label[i])\n",
        "                    batch_index += 1\n",
        "                    if batch_index == batch_size:\n",
        "                        yield feature_array, label_array\n",
        "                        batch_index = 0\n",
        "                        feature_array, label_array = np.zeros((batch_size, max_seg, max_word)), np.zeros((batch_size, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCbWOTVnM6QX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' Slice a piece from one dimension.\n",
        "\n",
        "The layer would slice the `index`th dimension from `target_dim` dimension of\n",
        "the input tensor, which have `total_dim` dimensions, then squeeze the tensor\n",
        "over the sliced dimension.\n",
        "\n",
        "Args:\n",
        "    total_dim (int): The total number of dimensions of the input tensor.\n",
        "    target_dim (int): The index of the dimension that need to slice.\n",
        "    index (int): The index of the dimension to keep in the slicing operation.\n",
        "\n",
        "Returns:\n",
        "    (Model): A keras model that implement the operation.\n",
        "'''\n",
        "def __get_filter_layer(total_dim, target_dim, index):\n",
        "    def tensor_filter(tensor_in):\n",
        "        nonlocal index\n",
        "        begin = [0 if i != target_dim else index for i in range(total_dim)]\n",
        "        size = [-1 if i != target_dim else 1 for i in range(total_dim)]\n",
        "        return tf.squeeze(tf.slice(tensor_in, begin, size), axis=target_dim)\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Lambda(tensor_filter)\n",
        "    ])\n",
        "\n",
        "\n",
        "''' Implement `submodel` for each slice of tensor.\n",
        "\n",
        "The model would slice its input tensor into pieces using `__get_filter_layer` \n",
        "along `branch_index`th dimension, then for each slice, implement submodel, \n",
        "finally the outputs of different submodels would be concated and reshaped to \n",
        "meet the demand of output.\n",
        "\n",
        "Args:\n",
        "    input_shape tuple(int): The shape of the input tensor.\n",
        "    branch_index (int): The index of the dimension to slice, start from 0 as \n",
        "        sample amount dimension.\n",
        "    output_shape tuple(int): The shape of the output tensor.\n",
        "    submodel (Model): The model to apply to different slices.\n",
        "    args (dict): The argument dictionary for `submodel`.\n",
        "'''\n",
        "def __get_branch_model(input_shape, branch_index, output_shape, submodel, args={}):\n",
        "    model_input = tf.keras.Input(input_shape)\n",
        "    sliced_inputs = [__get_filter_layer(len(input_shape) + 1, branch_index, i)(model_input) \n",
        "                     for i in range(input_shape[branch_index - 1])]\n",
        "    sub_instance = submodel(**args)\n",
        "    branch_models = [sub_instance(sliced_inputs[i]) \n",
        "                     for i in range(input_shape[branch_index - 1])]\n",
        "    concated_layers = tf.keras.layers.Concatenate()(branch_models)\n",
        "    model_output = tf.keras.layers.Reshape(output_shape)(concated_layers)\n",
        "    return tf.keras.Model(model_input, model_output)\n",
        "\n",
        "\n",
        "''' A CNN unit to encode segment with single kernel height.\n",
        "\n",
        "The unit would apply a convolution to its input to get a 2-dimensional \n",
        "tensor, then apply max overtime pooling to get a single dimensional tensor.\n",
        "\n",
        "Args:\n",
        "    input_shape ((int, int)): The shape of segment matrix. (word_max, w2v_len)\n",
        "    hidden_feature_dim (int): The dimension of the hidden feature.\n",
        "    kernel_height (int): The height of the convolution kernel.\n",
        "\n",
        "Returns:\n",
        "    (Model): The CNN model to encode the segment matrix.\n",
        "'''\n",
        "def __get_sentence_encode_unit(input_shape, hidden_feature_dim, kernel_height, eta):\n",
        "    cnned_height = input_shape[0] - kernel_height + 1\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv1D(\n",
        "            filters=hidden_feature_dim, \n",
        "            kernel_size=kernel_height,\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(eta)\n",
        "        ),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.ReLU(),\n",
        "        tf.keras.layers.MaxPool1D(cnned_height)\n",
        "    ])\n",
        "\n",
        "\n",
        "''' A CNN unit to encode segment with multiple kernel heights\n",
        "\n",
        "The unit would apply operation defined in `__get_sentence_encode_unit` for \n",
        "different kernel heights, then concat the result as a 1-dimensional tensor.\n",
        "\n",
        "Args:\n",
        "    input_shape ((int, int)): The shape of the document. (word_max, w2v_len)\n",
        "    hidden_feature_dim (int): The dimension of the hidden feature.\n",
        "    kernel_heights ([int]): The list of the kernel heights.\n",
        "\n",
        "Returns:\n",
        "    (Model): The CNN model to encode the segment matrix.\n",
        "'''\n",
        "def __get_multi_kernel_encode_unit(input_shape, hidden_feature_dim, kernel_heights, eta):\n",
        "    model_input = tf.keras.Input(input_shape)\n",
        "    cnn_layers = [__get_sentence_encode_unit((input_shape), hidden_feature_dim, h, eta)\n",
        "                     (model_input) for h in kernel_heights]\n",
        "    concated_layers = tf.keras.layers.Concatenate()(cnn_layers)\n",
        "    model_output = tf.keras.layers.Flatten()(concated_layers)\n",
        "    return tf.keras.Model(model_input, model_output)\n",
        "\n",
        "\n",
        "''' The softmax linear classifier for predicting segment sentiment.\n",
        "\n",
        "Args:\n",
        "    class_cnt (int): Number of classes in the classification.\n",
        "    dropout_rate (int): The drop out rate of the drop out layer.\n",
        "\n",
        "Returns:\n",
        "    (Model): The softmax linear classifier to predict segment sentiment.\n",
        "'''\n",
        "def __get_seg_classifier_unit(class_cnt, dropout_rate, eta):\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Dense(\n",
        "            units=class_cnt, \n",
        "            activation='softmax',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(eta),\n",
        "            bias_regularizer=tf.keras.regularizers.l2(eta)\n",
        "        )\n",
        "    ])\n",
        "\n",
        "\n",
        "''' The unit to get the attention weight for a segment from hidden feature.\n",
        "\n",
        "Args:\n",
        "    gru_feature_dim: The number of out dimensions of GRU layer.\n",
        "    dropout_rate: The drop out rate of the drop out layer.\n",
        "\n",
        "Returns:\n",
        "    (Model): The model for predicting attention weight for a segment.\n",
        "\n",
        "'''\n",
        "def __get_attention_unit(attention_key_dim, dropout_rate, eta):\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dropout(dropout_rate),\n",
        "        tf.keras.layers.Dense(\n",
        "            units=attention_key_dim, \n",
        "            activation='tanh',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(eta),\n",
        "            bias_regularizer=tf.keras.regularizers.l2(eta)\n",
        "        ),\n",
        "        tf.keras.layers.Dense(\n",
        "            units=1, \n",
        "            use_bias=False, \n",
        "            activation='softmax',\n",
        "            bias_regularizer=tf.keras.regularizers.l2(eta)\n",
        "        )\n",
        "    ])\n",
        "\n",
        "\n",
        "''' A bidirectional-GRU unit to extract the hidden vectors.\n",
        "\n",
        "The hidden vectors are used to predict the attention weights of the model.\n",
        "\n",
        "Args:\n",
        "    gru_feature_dim (int): The output dimension of the GRU layer.\n",
        "\n",
        "Returns:\n",
        "    (Model): The bidirectional-GRU unit to predict the hidden vectors.\n",
        "'''\n",
        "def __get_bidirectional_gru_unit(gru_feature_dim):\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Bidirectional(\n",
        "            tf.keras.layers.GRU(gru_feature_dim, return_sequences=True)\n",
        "        )\n",
        "    ])\n",
        "\n",
        "\n",
        "def __get_merge_unit(class_cnt, eta):\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dot(axes=1),\n",
        "        tf.keras.layers.Lambda(lambda x: tf.keras.backend.squeeze(x, 1)),\n",
        "        tf.keras.layers.Dense(\n",
        "            units=class_cnt, \n",
        "            activation='softmax',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(eta),\n",
        "            bias_regularizer=tf.keras.regularizers.l2(eta)\n",
        "        )\n",
        "    ])\n",
        "    \n",
        "\n",
        "''' A method to test the accuracy of the model, as well as precision, recal and F1 score\n",
        "\n",
        "Args:\n",
        "    model (Compiled Model): A tf.keras model for prediction\n",
        "    generator (generator): A generator to generate batches of test data\n",
        "    class_cnt (int): Number of classes of the label\n",
        "'''\n",
        "def performance_judge(model, generator, class_cnt):\n",
        "    eps = np.finfo(float).eps\n",
        "    accuracy, precisions, recalls, f1s = [], [], [], []\n",
        "    for i, (features, labels) in enumerate(generator):\n",
        "        predicted = model.predict(features)\n",
        "        precisions.append([])\n",
        "        recalls.append([])\n",
        "        f1s.append([])\n",
        "        contingency_table = np.zeros((class_cnt, class_cnt))\n",
        "        for index in range(features.shape[0]):\n",
        "            contingency_table[int(labels[index][0])][np.argmax(predicted[index])] += 1\n",
        "        accuracy.append(np.trace(contingency_table) / features.shape[0])\n",
        "        for index in range(class_cnt):\n",
        "            pass\n",
        "            precisions[i].append(contingency_table[index][index] / (np.sum(contingency_table[:, index]) + eps))\n",
        "            recalls[i].append(contingency_table[index][index] / (np.sum(contingency_table[index, :]) + eps))\n",
        "            f1s[i].append(2 * precisions[i][-1] * recalls[i][-1] / ((precisions[i][-1] + recalls[i][-1]) + eps))\n",
        "    precisions = [float(sum(l))/len(l) for l in zip(*precisions)]\n",
        "    recalls = [float(sum(l))/len(l) for l in zip(*recalls)]\n",
        "    f1s = [float(sum(l))/len(l) for l in zip(*f1s)]\n",
        "    print('Accuracy:', round(reduce(lambda x, y: x + y, accuracy) / len(accuracy), 3))\n",
        "    for index in range(class_cnt):\n",
        "        print('_____ Class', index, '_____')\n",
        "        print('Precision\\t', round(precisions[index], 3))\n",
        "        print('Recall\\t\\t', round(recalls[index], 3))\n",
        "        print('F1 Score\\t', round(f1s[index], 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be9L2dRmz37F",
        "colab_type": "code",
        "outputId": "a9f93177-416b-4ca1-fe42-bcba1948a755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "print('Constructing Model ...', end='')\n",
        "\n",
        "model_input = tf.keras.Input((max_seg, max_word))\n",
        "\n",
        "embedding_layer = tf.keras.layers.Embedding(\n",
        "    input_dim=w2v.shape[0], \n",
        "    output_dim=w2v_len, \n",
        "    weights=[w2v], \n",
        "    input_length=max_word, \n",
        "    trainable=False\n",
        ")(model_input)\n",
        "\n",
        "encoding_model = __get_branch_model(\n",
        "    input_shape=(max_seg, max_word, w2v_len), \n",
        "    branch_index=1, \n",
        "    output_shape=(max_seg, len(kernel_heights) * hidden_feature_dim), \n",
        "    submodel=__get_multi_kernel_encode_unit, \n",
        "    args={\n",
        "        'input_shape': (max_word, w2v_len), \n",
        "        'hidden_feature_dim': hidden_feature_dim,\n",
        "        'kernel_heights': kernel_heights, \n",
        "        'eta': eta\n",
        "    }\n",
        ")(embedding_layer)\n",
        "\n",
        "biglu_model = __get_bidirectional_gru_unit(\n",
        "    gru_feature_dim=gru_feature_dim\n",
        ")(encoding_model)\n",
        "\n",
        "attention_model = __get_branch_model(\n",
        "    input_shape=(max_seg, 2 * gru_feature_dim), \n",
        "    branch_index=1, \n",
        "    output_shape=(max_seg, 1), \n",
        "    submodel=__get_attention_unit,\n",
        "    args={\n",
        "        'attention_key_dim': attention_key_dim,\n",
        "        'dropout_rate': dropout_rate,\n",
        "        'eta': eta\n",
        "    }\n",
        ")(biglu_model)\n",
        "\n",
        "classification_model = __get_branch_model(\n",
        "    input_shape=(max_seg, len(kernel_heights) * hidden_feature_dim), \n",
        "    branch_index=1, \n",
        "    output_shape=(max_seg, level_class_cnt), \n",
        "    submodel=__get_seg_classifier_unit,\n",
        "    args={\n",
        "        'class_cnt': level_class_cnt,\n",
        "        'dropout_rate': dropout_rate,\n",
        "        'eta': eta\n",
        "    }\n",
        ")(encoding_model)\n",
        "\n",
        "merge_model = __get_merge_unit(\n",
        "    class_cnt=level_class_cnt,\n",
        "    eta=eta\n",
        ")([attention_model, classification_model])\n",
        "\n",
        "model = tf.keras.Model(model_input, merge_model)\n",
        "\n",
        "print('\\rModel Constructed. Compiling ...', end='')\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print('\\rModel Compiled.')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0703 07:55:11.816193 140706548647808 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Constructing Model ..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0703 07:55:15.232728 140706548647808 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0703 07:55:20.177589 140706548647808 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0703 07:55:20.179037 140706548647808 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0703 07:55:20.180226 140706548647808 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\rModel Constructed. Compiling ...\rModel Compiled.\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 12, 34)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 12, 34, 300)  59283000    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Model)                 (None, 12, 300)      361500      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "sequential_15 (Sequential)      (None, 12, 100)      105300      model_1[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Model)                 (None, 12, 1)        10200       sequential_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "model_3 (Model)                 (None, 12, 5)        1505        model_1[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_42 (Sequential)      (None, 5)            30          model_2[1][0]                    \n",
            "                                                                 model_3[1][0]                    \n",
            "==================================================================================================\n",
            "Total params: 59,761,535\n",
            "Trainable params: 477,935\n",
            "Non-trainable params: 59,283,600\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2V627zAKDVP",
        "colab_type": "code",
        "outputId": "d5f2b268-0e20-4718-a8a8-2dbfa48f1b60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "model.fit_generator(\n",
        "    data_generator(train_batches), \n",
        "    steps_per_epoch=(sample_amount * (1 - test_percentage) // batch_size) - 1,\n",
        "    epochs=epochs\n",
        ")\n",
        "\n",
        "# model.save(model_out_path)\n",
        "\n",
        "print('########## Training Error ##########')\n",
        "performance_judge(model, data_generator(train_batches, epochs=1), level_class_cnt)\n",
        "\n",
        "print('############ Test Error ############')\n",
        "performance_judge(model, data_generator(test_batches, epochs=1), level_class_cnt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0703 07:55:29.416139 140706548647808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1279/1279 [==============================] - 284s 222ms/step - loss: 1.6026 - acc: 0.3381\n",
            "Epoch 2/25\n",
            "1279/1279 [==============================] - 265s 207ms/step - loss: 1.4154 - acc: 0.3889\n",
            "Epoch 3/25\n",
            "1279/1279 [==============================] - 270s 211ms/step - loss: 1.3692 - acc: 0.4107\n",
            "Epoch 4/25\n",
            "1279/1279 [==============================] - 268s 210ms/step - loss: 1.3215 - acc: 0.4395\n",
            "Epoch 5/25\n",
            "1279/1279 [==============================] - 267s 209ms/step - loss: 1.2841 - acc: 0.4634\n",
            "Epoch 6/25\n",
            "1279/1279 [==============================] - 271s 212ms/step - loss: 1.2679 - acc: 0.4739\n",
            "Epoch 7/25\n",
            "1279/1279 [==============================] - 268s 209ms/step - loss: 1.2523 - acc: 0.4832\n",
            "Epoch 8/25\n",
            "1279/1279 [==============================] - 267s 209ms/step - loss: 1.2399 - acc: 0.4884\n",
            "Epoch 9/25\n",
            " 494/1279 [==========>...................] - ETA: 2:46 - loss: 1.2282 - acc: 0.4943"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KB7oKZq3b7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Document level baseline\n",
        "\n",
        "model_input = tf.keras.Input((max_seg, max_word))\n",
        "\n",
        "flattened = tf.keras.layers.Flatten()(model_input)\n",
        "\n",
        "embedding_layer = tf.keras.layers.Embedding(\n",
        "    input_dim=w2v.shape[0], \n",
        "    output_dim=w2v_len, \n",
        "    weights=[w2v], \n",
        "    input_length=max_word, \n",
        "    trainable=False\n",
        ")(flattened)\n",
        "\n",
        "encoding_model = __get_multi_kernel_encode_unit(\n",
        "    input_shape=(max_seg * max_word, w2v_len),\n",
        "    hidden_feature_dim=hidden_feature_dim,\n",
        "    kernel_heights=kernel_heights\n",
        ")(embedding_layer)\n",
        "\n",
        "classification_model = __get_seg_classifier_unit(\n",
        "    class_cnt=level_class_cnt,\n",
        "    dropout_rate=dropout_rate\n",
        ")(encoding_model)\n",
        "\n",
        "model = tf.keras.Model(model_input, classification_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pViUgsD_Wx3K",
        "colab_type": "code",
        "outputId": "65f7eaad-0b46-401f-e93e-1d18e3e8321d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fake_x = np.random.rand(1000, 20, 300)\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='tanh')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.predict(fake_x).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 20, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfmJ8_3fNJxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}