{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJNBh-i-1ppt"
   },
   "source": [
    "### Package Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "PPiu0FUpDXOg",
    "outputId": "999d1007-abc6-4616-ea78-85b9524bcb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import datetime\n",
    "from random import shuffle\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "# !pip install tensorflow-gpu\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O7hkUVjJ1sJq"
   },
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q12ET7dhDjBi"
   },
   "outputs": [],
   "source": [
    "max_seg = 10\n",
    "max_word = 18\n",
    "level_class_cnt = 3\n",
    "test_percentage = 0.2\n",
    "\n",
    "dropout_rate = 0.5\n",
    "eta = 1e-4\n",
    "hidden_feature_dim = 100\n",
    "attention_key_dim = 100\n",
    "gru_feature_dim = 50\n",
    "kernel_heights = [3, 4, 5]\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "\n",
    "input_path = '/content/gdrive/My Drive/data_source/milnet/model_inputs/electronics.hdf5'\n",
    "w2v_weights_path = '/content/gdrive/My Drive/data_source/milnet/model_inputs/fasttext_weights.npy'\n",
    "# tensorboard_log_dir = '/Users/Frost/Desktop/log/'\n",
    "\n",
    "model_out_path = '/content/gdrive/My Drive/data_source/milnet/results/model_stop_w2v_35_11_edu.h5'\n",
    "\n",
    "sample_amount = 0\n",
    "mini_batch_cnt = 0\n",
    "with h5py.File(input_path) as in_file:\n",
    "    for index in range(len(in_file['label/'].keys())):\n",
    "        mini_batch_cnt += 1\n",
    "        sample_amount += len(in_file['label/' + str(index)])\n",
    "batch_indices = [*range(mini_batch_cnt)]\n",
    "shuffle(batch_indices)\n",
    "train_batches = batch_indices[0:int(mini_batch_cnt * (1 - test_percentage))]\n",
    "test_batches = batch_indices[int(mini_batch_cnt * (1 - test_percentage)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFW8uq364fNC"
   },
   "source": [
    "### Data Preloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g5kI-lWj4ixw"
   },
   "outputs": [],
   "source": [
    "w2v = np.load(w2v_weights_path, allow_pickle=True)\n",
    "w2v_len = w2v.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lc9RYq7e1zTi"
   },
   "source": [
    "### Data Loading Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FDDd0ZLhESr2"
   },
   "outputs": [],
   "source": [
    "def __label_map(raw_label):\n",
    "    if raw_label < 2:\n",
    "        return 0\n",
    "    elif raw_label < 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def __balance_data(feature_array, label_array):\n",
    "    to_balance_indices = np.where(label_array != 1)[0]\n",
    "    removal_indices = np.random.choice(to_balance_indices, to_balance_indices.shape[0] // 2)\n",
    "    return np.delete(feature_array, removal_indices, axis=0), np.delete(label_array, removal_indices, axis=0)\n",
    "\n",
    "def data_generator(batch_indices, max_seg=max_seg, max_word=max_word, epochs=epochs, use_balance=True):\n",
    "    global batch_size, input_path\n",
    "    with h5py.File(input_path) as in_file:\n",
    "        feature_array, label_array = np.zeros((batch_size, max_seg, max_word)), np.zeros((batch_size, 1))\n",
    "        batch_index = 0\n",
    "        for _ in range(epochs):\n",
    "            shuffle(batch_indices)\n",
    "            for index in batch_indices:\n",
    "                doc, label = in_file['document/' + str(index)], in_file['label/' + str(index)]\n",
    "                random_doc_order = [*range(len(doc))]\n",
    "                shuffle(random_doc_order)\n",
    "                for i in random_doc_order:\n",
    "                    feature_array[batch_index] = doc[i][:max_seg, :max_word]\n",
    "                    label_array[batch_index] = __label_map(label[i])\n",
    "                    batch_index += 1\n",
    "                    if batch_index == batch_size:\n",
    "                        if use_balance:\n",
    "                            yield __balance_data(feature_array, label_array)\n",
    "                        else:\n",
    "                            yield feature_array, label_array\n",
    "                        batch_index = 0\n",
    "                        feature_array, label_array = np.zeros((batch_size, max_seg, max_word)), np.zeros((batch_size, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kz8ZWNWS11rJ"
   },
   "source": [
    "### Methods Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VCbWOTVnM6QX"
   },
   "outputs": [],
   "source": [
    "''' Slice a piece from one dimension.\n",
    "\n",
    "The layer would slice the `index`th dimension from `target_dim` dimension of\n",
    "the input tensor, which have `total_dim` dimensions, then squeeze the tensor\n",
    "over the sliced dimension.\n",
    "\n",
    "Args:\n",
    "    total_dim (int): The total number of dimensions of the input tensor.\n",
    "    target_dim (int): The index of the dimension that need to slice.\n",
    "    index (int): The index of the dimension to keep in the slicing operation.\n",
    "\n",
    "Returns:\n",
    "    (Model): A keras model that implement the operation.\n",
    "'''\n",
    "def __get_filter_layer(total_dim, target_dim, index):\n",
    "    def tensor_filter(tensor_in):\n",
    "        nonlocal index\n",
    "        begin = [0 if i != target_dim else index for i in range(total_dim)]\n",
    "        size = [-1 if i != target_dim else 1 for i in range(total_dim)]\n",
    "        return tf.squeeze(tf.slice(tensor_in, begin, size), axis=target_dim)\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Lambda(tensor_filter)\n",
    "    ])\n",
    "\n",
    "\n",
    "''' Implement `submodel` for each slice of tensor.\n",
    "\n",
    "The model would slice its input tensor into pieces using `__get_filter_layer` \n",
    "along `branch_index`th dimension, then for each slice, implement submodel, \n",
    "finally the outputs of different submodels would be concated and reshaped to \n",
    "meet the demand of output.\n",
    "\n",
    "Args:\n",
    "    input_shape tuple(int): The shape of the input tensor.\n",
    "    branch_index (int): The index of the dimension to slice, start from 0 as \n",
    "        sample amount dimension.\n",
    "    output_shape tuple(int): The shape of the output tensor.\n",
    "    submodel (Model): The model to apply to different slices.\n",
    "    args (dict): The argument dictionary for `submodel`.\n",
    "'''\n",
    "def get_branch_model(input_shape, branch_index, output_shape, submodel, args={}):\n",
    "    model_input = tf.keras.Input(input_shape)\n",
    "    sliced_inputs = [__get_filter_layer(len(input_shape) + 1, branch_index, i)(model_input) \n",
    "                     for i in range(input_shape[branch_index - 1])]\n",
    "    sub_instance = submodel(**args)\n",
    "    branch_models = [sub_instance(sliced_inputs[i]) \n",
    "                     for i in range(input_shape[branch_index - 1])]\n",
    "    expand_layer = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=1))\n",
    "    expanded_outputs = [expand_layer(branch_models[i]) for i in range(input_shape[0])]\n",
    "    concated_layer = tf.keras.layers.Concatenate(axis=1)(expanded_outputs)\n",
    "    return tf.keras.Model(model_input, concated_layer)\n",
    "\n",
    "\n",
    "''' A CNN unit to encode segment with single kernel height.\n",
    "\n",
    "The unit would apply a convolution to its input to get a 2-dimensional \n",
    "tensor, then apply max overtime pooling to get a single dimensional tensor.\n",
    "\n",
    "Args:\n",
    "    input_shape ((int, int)): The shape of segment matrix. (word_max, w2v_len)\n",
    "    hidden_feature_dim (int): The dimension of the hidden feature.\n",
    "    kernel_height (int): The height of the convolution kernel.\n",
    "    eta (float): The multiplier of the L2 regularizer term.\n",
    "\n",
    "Returns:\n",
    "    (Model): The CNN model to encode the segment matrix.\n",
    "'''\n",
    "def __get_sentence_encode_unit(input_shape, hidden_feature_dim, kernel_height, eta):\n",
    "    cnned_height = input_shape[0] - kernel_height + 1\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv1D(\n",
    "            filters=hidden_feature_dim, \n",
    "            kernel_size=kernel_height,\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(eta)\n",
    "        ),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.MaxPool1D(cnned_height)\n",
    "    ])\n",
    "\n",
    "\n",
    "''' A CNN unit to encode segment with multiple kernel heights\n",
    "\n",
    "The unit would apply operation defined in `__get_sentence_encode_unit` for \n",
    "different kernel heights, then concat the result as a 1-dimensional tensor.\n",
    "\n",
    "Args:\n",
    "    input_shape ((int, int)): The shape of the document. (word_max, w2v_len)\n",
    "    hidden_feature_dim (int): The dimension of the hidden feature.\n",
    "    kernel_heights ([int]): The list of the kernel heights.\n",
    "    eta (float): The multiplier of the L2 regularizer term.\n",
    "\n",
    "Returns:\n",
    "    (Model): The CNN model to encode the segment matrix.\n",
    "'''\n",
    "def __get_multi_kernel_encode_unit(input_shape, hidden_feature_dim, kernel_heights, eta):\n",
    "    model_input = tf.keras.Input(input_shape)\n",
    "    cnn_layers = [__get_sentence_encode_unit((input_shape), hidden_feature_dim, h, eta)\n",
    "                     (model_input) for h in kernel_heights]\n",
    "    concated_layers = tf.keras.layers.Concatenate()(cnn_layers)\n",
    "    model_output = tf.keras.layers.Flatten()(concated_layers)\n",
    "    return tf.keras.Model(model_input, model_output)\n",
    "\n",
    "\n",
    "''' The softmax linear classifier for predicting segment sentiment.\n",
    "\n",
    "Args:\n",
    "    class_cnt (int): Number of classes in the classification.\n",
    "    dropout_rate (int): The drop out rate of the drop out layer.\n",
    "    eta (float): The multiplier of the L2 regularizer term.\n",
    "\n",
    "Returns:\n",
    "    (Model): The softmax linear classifier to predict segment sentiment.\n",
    "'''\n",
    "def __get_seg_classifier_unit(class_cnt, dropout_rate, eta):\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(\n",
    "            units=class_cnt, \n",
    "            activation='softmax',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(eta),\n",
    "            bias_regularizer=tf.keras.regularizers.l2(eta)\n",
    "        )\n",
    "    ])\n",
    "\n",
    "\n",
    "''' The unit to get the attention weight for a segment from hidden feature.\n",
    "\n",
    "Args:\n",
    "    gru_feature_dim: The number of out dimensions of GRU layer.\n",
    "    dropout_rate: The drop out rate of the drop out layer.\n",
    "    eta (float): The multiplier of the L2 regularizer term.\n",
    "\n",
    "Returns:\n",
    "    (Model): The model for predicting attention weight for a segment.\n",
    "\n",
    "'''\n",
    "def __get_attention_unit(attention_key_dim, dropout_rate, eta):\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(\n",
    "            units=attention_key_dim, \n",
    "            activation='tanh',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(eta),\n",
    "            bias_regularizer=tf.keras.regularizers.l2(eta)\n",
    "        ),\n",
    "        tf.keras.layers.Dense(\n",
    "            units=1, \n",
    "            use_bias=False, \n",
    "            activation='softmax',\n",
    "            bias_regularizer=tf.keras.regularizers.l2(eta)\n",
    "        )\n",
    "    ])\n",
    "\n",
    "\n",
    "''' A bidirectional-GRU unit to extract the hidden vectors.\n",
    "\n",
    "The hidden vectors are used to predict the attention weights of the model.\n",
    "\n",
    "Args:\n",
    "    gru_feature_dim (int): The output dimension of the GRU layer.\n",
    "\n",
    "Returns:\n",
    "    (Model): The bidirectional-GRU unit to predict the hidden vectors.\n",
    "'''\n",
    "def get_bidirectional_gru_model(gru_feature_dim):\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Bidirectional(\n",
    "            tf.keras.layers.GRU(gru_feature_dim, return_sequences=True)\n",
    "        )\n",
    "    ])\n",
    "\n",
    "''' Merge the attention weights and the instance predictions.\n",
    "\n",
    "This model will merge the attentions and instance predictions using weighted sum.\n",
    "\n",
    "Args:\n",
    "    class_cnt (int): Number of classes in the classification.\n",
    "    eta (float): The multiplier of the L2 regularizer term.\n",
    "'''\n",
    "def get_merge_model(class_cnt, eta):\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dot(axes=1),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(\n",
    "            units=class_cnt, \n",
    "            activation='softmax',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(eta),\n",
    "            bias_regularizer=tf.keras.regularizers.l2(eta)\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "\n",
    "''' A method to test the accuracy of the model, as well as precision, recal and F1 score\n",
    "\n",
    "Args:\n",
    "    model (Compiled Model): A tf.keras model for prediction\n",
    "    generator (generator): A generator to generate batches of test data\n",
    "    class_cnt (int): Number of classes of the label\n",
    "'''\n",
    "def performance_judge(model, generator, class_cnt):\n",
    "    eps = np.finfo(float).eps\n",
    "    accuracy, precisions, recalls, f1s = [], [], [], []\n",
    "    for i, (features, labels) in enumerate(generator):\n",
    "        predicted = model.predict(features)\n",
    "        precisions.append([])\n",
    "        recalls.append([])\n",
    "        f1s.append([])\n",
    "        contingency_table = np.zeros((class_cnt, class_cnt))\n",
    "        for index in range(features.shape[0]):\n",
    "            contingency_table[int(labels[index][0])][np.argmax(predicted[index])] += 1\n",
    "        accuracy.append(np.trace(contingency_table) / features.shape[0])\n",
    "        for index in range(class_cnt):\n",
    "            pass\n",
    "            precisions[i].append(contingency_table[index][index] / (np.sum(contingency_table[:, index]) + eps))\n",
    "            recalls[i].append(contingency_table[index][index] / (np.sum(contingency_table[index, :]) + eps))\n",
    "            f1s[i].append(2 * precisions[i][-1] * recalls[i][-1] / ((precisions[i][-1] + recalls[i][-1]) + eps))\n",
    "    precisions = [float(sum(l))/len(l) for l in zip(*precisions)]\n",
    "    recalls = [float(sum(l))/len(l) for l in zip(*recalls)]\n",
    "    f1s = [float(sum(l))/len(l) for l in zip(*f1s)]\n",
    "    print('Accuracy:', round(reduce(lambda x, y: x + y, accuracy) / len(accuracy), 3))\n",
    "    for index in range(class_cnt):\n",
    "        print('_____ Class', index, '_____')\n",
    "        print('Precision\\t', round(precisions[index], 3))\n",
    "        print('Recall\\t\\t', round(recalls[index], 3))\n",
    "        print('F1 Score\\t', round(f1s[index], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ut68Yfyx19Fs"
   },
   "source": [
    "### Model Construction and Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "colab_type": "code",
    "id": "be9L2dRmz37F",
    "outputId": "763064d5-5723-416e-c4b5-88fe4283e0b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0711 18:54:15.965303 140647093032832 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Model ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0711 18:54:19.315662 140647093032832 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0711 18:54:23.511056 140647093032832 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0711 18:54:23.512325 140647093032832 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0711 18:54:23.513355 140647093032832 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Compiled.\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10, 18)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 10, 18, 300)  56619900    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 10, 300)      361500      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sequential_13 (Sequential)      (None, 10, 100)      105300      model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 10, 1)        10200       sequential_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 10, 3)        903         model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_36 (Sequential)      (None, 3)            12          model_2[1][0]                    \n",
      "                                                                 model_3[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 57,097,815\n",
      "Trainable params: 477,315\n",
      "Non-trainable params: 56,620,500\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Constructing Model ...', end='')\n",
    "\n",
    "model_input = tf.keras.Input((max_seg, max_word))\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=w2v.shape[0], \n",
    "    output_dim=w2v_len, \n",
    "    weights=[w2v], \n",
    "    input_length=max_word, \n",
    "    trainable=False\n",
    ")(model_input)\n",
    "\n",
    "encoding_model = get_branch_model(\n",
    "    input_shape=(max_seg, max_word, w2v_len), \n",
    "    branch_index=1, \n",
    "    output_shape=(max_seg, len(kernel_heights) * hidden_feature_dim), \n",
    "    submodel=__get_multi_kernel_encode_unit, \n",
    "    args={\n",
    "        'input_shape': (max_word, w2v_len), \n",
    "        'hidden_feature_dim': hidden_feature_dim,\n",
    "        'kernel_heights': kernel_heights, \n",
    "        'eta': eta\n",
    "    }\n",
    ")(embedding_layer)\n",
    "\n",
    "biglu_model = get_bidirectional_gru_model(\n",
    "    gru_feature_dim=gru_feature_dim\n",
    ")(encoding_model)\n",
    "\n",
    "attention_model = get_branch_model(\n",
    "    input_shape=(max_seg, 2 * gru_feature_dim), \n",
    "    branch_index=1, \n",
    "    output_shape=(max_seg, 1), \n",
    "    submodel=__get_attention_unit,\n",
    "    args={\n",
    "        'attention_key_dim': attention_key_dim,\n",
    "        'dropout_rate': dropout_rate,\n",
    "        'eta': eta\n",
    "    }\n",
    ")(biglu_model)\n",
    "\n",
    "classification_model = get_branch_model(\n",
    "    input_shape=(max_seg, len(kernel_heights) * hidden_feature_dim), \n",
    "    branch_index=1, \n",
    "    output_shape=(max_seg, level_class_cnt), \n",
    "    submodel=__get_seg_classifier_unit,\n",
    "    args={\n",
    "        'class_cnt': level_class_cnt,\n",
    "        'dropout_rate': dropout_rate,\n",
    "        'eta': eta\n",
    "    }\n",
    ")(encoding_model)\n",
    "\n",
    "merge_model = get_merge_model(\n",
    "    class_cnt=level_class_cnt,\n",
    "    eta=eta\n",
    ")([attention_model, classification_model])\n",
    "\n",
    "model = tf.keras.Model(model_input, merge_model)\n",
    "\n",
    "print('\\rModel Constructed. Compiling ...', end='')\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print('\\rModel Compiled.')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AoPz2QJZ2EIh"
   },
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "colab_type": "code",
    "id": "m2V627zAKDVP",
    "outputId": "569d7499-9269-4880-ace0-c0aff09737e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0711 18:55:20.470489 140647093032832 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "   1/1279 [..............................] - ETA: 4:59:01 - loss: 2.7637 - acc: 0.3945"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0711 18:55:33.770370 140647093032832 callbacks.py:257] Method (on_train_batch_end) is slow compared to the batch update (0.291299). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279/1279 [==============================] - 237s 185ms/step - loss: 1.2668 - acc: 0.3848\n",
      "Epoch 2/10\n",
      "1279/1279 [==============================] - 206s 161ms/step - loss: 1.0800 - acc: 0.4124\n",
      "Epoch 3/10\n",
      "1279/1279 [==============================] - 203s 158ms/step - loss: 1.0659 - acc: 0.4106\n",
      "Epoch 4/10\n",
      "1279/1279 [==============================] - 200s 156ms/step - loss: 1.0606 - acc: 0.4099\n",
      "Epoch 5/10\n",
      "1279/1279 [==============================] - 201s 157ms/step - loss: 1.0587 - acc: 0.4097\n",
      "Epoch 6/10\n",
      " 171/1279 [===>..........................] - ETA: 2:55 - loss: 1.0557 - acc: 0.4157"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4a880624eeee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_amount\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtest_percentage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logdir = os.path.join('logs', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "model.fit_generator(\n",
    "    data_generator(train_batches, use_balance=False), \n",
    "    steps_per_epoch=(sample_amount * (1 - test_percentage) // batch_size) - 1,\n",
    "    epochs=epochs,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "# model.save(model_out_path)\n",
    "\n",
    "print('########## Training Error ##########')\n",
    "performance_judge(model, data_generator(train_batches, epochs=1), level_class_cnt)\n",
    "\n",
    "print('############ Test Error ############')\n",
    "performance_judge(model, data_generator(test_batches, epochs=1), level_class_cnt)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "milnet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
