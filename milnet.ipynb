{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "milnet_functional.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWMavp6RwjYN",
        "colab_type": "code",
        "outputId": "fddc8d84-5329-4b66-a9d0-ab0b925cdf5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import h5py\n",
        "import os\n",
        "import pickle\n",
        "import datetime\n",
        "from random import shuffle\n",
        "from functools import reduce\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "# !pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48qgVjFhxHcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seg = 7\n",
        "max_word = 18\n",
        "# max_seg = 11\n",
        "# max_word = 7\n",
        "max_doc = 60\n",
        "level_class_cnt = 3\n",
        "\n",
        "test_percentage = 0.1\n",
        "validation_percentage = 0.1\n",
        "\n",
        "batch_size = 512\n",
        "epochs = 8\n",
        "\n",
        "input_path = '/content/gdrive/My Drive/data_source/milnet/model_inputs/gourmet.hdf5'\n",
        "w2v_weights_path = '/content/gdrive/My Drive/data_source/milnet/model_inputs/w2v_weights.npy'\n",
        "\n",
        "model_out_path = '/content/gdrive/My Drive/data_source/milnet/results/gourmet_sentence_c3_w2v.h5'\n",
        "log_out_dir = '/content/gdrive/My Drive/data_source/milnet/log/'\n",
        "\n",
        "sample_amount = 0\n",
        "mini_batch_cnt = 0\n",
        "with h5py.File(input_path) as in_file:\n",
        "    for index in range(len(in_file['label/'].keys())):\n",
        "        mini_batch_cnt += 1\n",
        "        sample_amount += len(in_file['label/' + str(index)])\n",
        "batch_indices = [*range(mini_batch_cnt)]\n",
        "shuffle(batch_indices)\n",
        "\n",
        "train_batches = batch_indices[0:int(mini_batch_cnt * (1 - test_percentage - validation_percentage))]\n",
        "validation_batches = batch_indices[int(mini_batch_cnt * (1 - test_percentage - validation_percentage)): int(mini_batch_cnt * (1 - test_percentage))]\n",
        "test_batches = batch_indices[int(mini_batch_cnt * (1 - test_percentage)):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4YWIJU1x0pK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v = np.load(w2v_weights_path, allow_pickle=True)\n",
        "w2v_len = w2v.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKyAnkJtxMKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def __label_map(raw_label):\n",
        "    if raw_label == 1 or raw_label == 2:\n",
        "        return 0\n",
        "    elif raw_label == 3:\n",
        "        return 1\n",
        "    else:\n",
        "        return 2\n",
        "\n",
        "def __balance_data(feature_array, label_array):\n",
        "    to_balance_indices = np.concatenate([np.where(label_array == 2)[0], np.where(label_array == 4)[0]])\n",
        "    return np.delete(feature_array, to_balance_indices, axis=0), np.delete(label_array, to_balance_indices, axis=0)\n",
        "\n",
        "def data_generator(batch_indices, max_doc=max_doc, max_seg=max_seg, max_word=max_word, epochs=epochs, use_balance=True):\n",
        "    global batch_size, input_path\n",
        "    with h5py.File(input_path) as in_file:\n",
        "        feature_array, label_array = np.zeros((batch_size, max_seg, max_word)), np.zeros((batch_size, 1))\n",
        "        batch_index = 0\n",
        "        for _ in range(epochs):\n",
        "            shuffle(batch_indices)\n",
        "            for index in batch_indices:\n",
        "                doc, label = in_file['document/' + str(index)], in_file['label/' + str(index)]\n",
        "                random_doc_order = [*range(len(doc))]\n",
        "                shuffle(random_doc_order)\n",
        "                for i in random_doc_order:\n",
        "                    feature_array[batch_index] = doc[i][:max_seg, :max_word]\n",
        "                    label_array[batch_index] = label[i]\n",
        "                    batch_index += 1\n",
        "                    if batch_index == batch_size:\n",
        "                        if use_balance:\n",
        "                            feature_array, label_array = __balance_data(feature_array, label_array)\n",
        "                        yield feature_array, np.array([np.array([__label_map(l[0])]) for l in label_array])\n",
        "                        batch_index = 0\n",
        "                        feature_array, label_array = np.zeros((batch_size, max_seg, max_word)), np.zeros((batch_size, 1))\n",
        "\n",
        "def get_data(batch_indices, max_seg=max_seg, max_word=max_word):\n",
        "    global input_path\n",
        "    with h5py.File(input_path) as in_file:\n",
        "        sample_amount = sum([len(in_file['document/' + str(i)]) for i in batch_indices])\n",
        "        feature_array, label_array = np.zeros((sample_amount, max_seg, max_word)), np.zeros((sample_amount, 1))\n",
        "        batch_index = 0\n",
        "        cnt = 0\n",
        "        for index in batch_indices:\n",
        "            doc, label = in_file['document/' + str(index)], in_file['label/' + str(index)]\n",
        "            for i in range(len(doc)):\n",
        "                feature_array[cnt] = doc[i][:max_seg, :max_word]\n",
        "                label_array[cnt] = __label_map(label[i])\n",
        "                cnt += 1\n",
        "        return feature_array, label_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckW9Pp-xylSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shared_sublayer_cache = {}\n",
        "\n",
        "def branch_execute(layer_in, sublayer, args={}):\n",
        "    instance_cnt = layer_in.shape[1]\n",
        "    sliced_inputs = [tf.keras.layers.Lambda(lambda x: x[:,i])(layer_in) \n",
        "                     for i in range(instance_cnt)]\n",
        "    branch_layers = [sublayer(**{**{'layer_in': sliced_inputs[i]}, **args}) \n",
        "                     for i in range(instance_cnt)]\n",
        "    expand_layer = tf.keras.layers.Lambda(lambda x: tf.keras.backend.expand_dims(x, axis=1))\n",
        "    expanded_layers = [expand_layer(branch_layers[i]) for i in range(instance_cnt)]\n",
        "    concated_layer = tf.keras.layers.Concatenate(axis=1)(expanded_layers)\n",
        "    return concated_layer\n",
        "\n",
        "def __sentence_encode_layer_share(layer_in, hidden_feature_dim, kernel_height, eta):\n",
        "    cnned_height = layer_in.shape[1] - kernel_height + 1\n",
        "    global shared_sublayer_cache\n",
        "    if 'shared_sentence_encode_sublayers' + str(kernel_height) not in shared_sublayer_cache:\n",
        "        shared_sublayer_cache['shared_sentence_encode_sublayers' + str(kernel_height)] = {\n",
        "            'conv_layer': tf.keras.layers.Conv1D(\n",
        "                filters=hidden_feature_dim,\n",
        "                kernel_size=kernel_height,\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(eta)\n",
        "            ),\n",
        "            'batch_normalize_layer': tf.keras.layers.BatchNormalization(\n",
        "            ),\n",
        "            'relu_layer': tf.keras.layers.ReLU(\n",
        "            ),\n",
        "            'max_pool_layer': tf.keras.layers.MaxPool1D(\n",
        "                (cnned_height,)\n",
        "            )\n",
        "        }\n",
        "    shared_layers = shared_sublayer_cache['shared_sentence_encode_sublayers' + str(kernel_height)]\n",
        "    conv_layer = shared_layers['conv_layer'](layer_in)\n",
        "    batch_normalize_layer = shared_layers['batch_normalize_layer'](conv_layer)\n",
        "    relu_layer = shared_layers['relu_layer'](batch_normalize_layer)\n",
        "    max_pool_layer = shared_layers['max_pool_layer'](relu_layer)\n",
        "    return max_pool_layer\n",
        "\n",
        "def __multi_kernel_encode_layer(layer_in, hidden_feature_dim, kernel_heights, eta):\n",
        "    cnn_layers = [__sentence_encode_layer_share(layer_in, hidden_feature_dim, h, eta) \n",
        "                  for h in kernel_heights]\n",
        "    concated_layer = tf.keras.layers.Concatenate()(cnn_layers)\n",
        "    flatten_layer = tf.keras.layers.Flatten()(concated_layer)\n",
        "    return flatten_layer\n",
        "\n",
        "def __seg_classifier_layer_share(layer_in, class_cnt, dropout_rate, eta):\n",
        "    global shared_sublayer_cache\n",
        "    if 'shared_seg_classifier_sublayers' not in shared_sublayer_cache:\n",
        "        shared_sublayer_cache['shared_seg_classifier_sublayers'] = {\n",
        "            'drop_out_layer': tf.keras.layers.Dropout(\n",
        "                dropout_rate\n",
        "            ),\n",
        "            'dense_layer': tf.keras.layers.Dense(\n",
        "                units=class_cnt,\n",
        "                activation='softmax',\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(eta),\n",
        "                bias_regularizer=tf.keras.regularizers.l2(eta)\n",
        "            )\n",
        "        }\n",
        "    shared_layers = shared_sublayer_cache['shared_seg_classifier_sublayers']\n",
        "    drop_out_layer = shared_layers['drop_out_layer'](layer_in)\n",
        "    dense_layer = shared_layers['dense_layer'](drop_out_layer)\n",
        "    return dense_layer\n",
        "\n",
        "def __attention_layer_share(layer_in, attention_key_dim, dropout_rate, eta):\n",
        "    global shared_sublayer_cache\n",
        "    if 'shared_attention_sublayers' not in shared_sublayer_cache:\n",
        "        shared_sublayer_cache['shared_attention_sublayers'] = {\n",
        "            'drop_out_layer': tf.keras.layers.Dropout(\n",
        "                dropout_rate\n",
        "            ),\n",
        "            'dense_layer': tf.keras.layers.Dense(\n",
        "                units=attention_key_dim, \n",
        "                activation='tanh',\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(eta),\n",
        "                bias_regularizer=tf.keras.regularizers.l2(eta)\n",
        "            ),\n",
        "            'nobias_dense_layer': tf.keras.layers.Dense(\n",
        "                units=1, \n",
        "                use_bias=False, \n",
        "                bias_regularizer=tf.keras.regularizers.l2(eta)\n",
        "            )\n",
        "        }\n",
        "    shared_layers = shared_sublayer_cache['shared_attention_sublayers']\n",
        "    drop_out_layer = shared_layers['drop_out_layer'](layer_in)\n",
        "    dense_layer = shared_layers['dense_layer'](drop_out_layer)\n",
        "    nobias_dense_layer = shared_layers['nobias_dense_layer'](dense_layer)\n",
        "    return nobias_dense_layer\n",
        "\n",
        "def bidirectional_gru_layer(layer_in, gru_feature_dim):\n",
        "    bidirectional_layer = tf.keras.layers.Bidirectional(\n",
        "        tf.keras.layers.GRU(gru_feature_dim, return_sequences=True)\n",
        "    )(layer_in)\n",
        "    return bidirectional_layer\n",
        "\n",
        "def merge_layer(layer_in, class_cnt, eta):\n",
        "    dot_layer = tf.keras.layers.Dot(axes=1)(layer_in)\n",
        "    flatten_layer = tf.keras.layers.Flatten()(dot_layer)\n",
        "    dense_layer = tf.keras.layers.Dense(\n",
        "        units=class_cnt, \n",
        "        activation='softmax',\n",
        "        kernel_regularizer=tf.keras.regularizers.l2(eta),\n",
        "        bias_regularizer=tf.keras.regularizers.l2(eta)\n",
        "    )(flatten_layer)\n",
        "    return dense_layer\n",
        "\n",
        "def performance_judge(model, generator, class_cnt):\n",
        "    eps = np.finfo(float).eps\n",
        "    accuracy, precisions, recalls, f1s = [], [], [], []\n",
        "    for i, (features, labels) in enumerate(generator):\n",
        "        predicted = model.predict(features)\n",
        "        precisions.append([])\n",
        "        recalls.append([])\n",
        "        f1s.append([])\n",
        "        contingency_table = np.zeros((class_cnt, class_cnt))\n",
        "        for index in range(features.shape[0]):\n",
        "            contingency_table[int(labels[index][0])][np.argmax(predicted[index])] += 1\n",
        "        accuracy.append(np.trace(contingency_table) / features.shape[0])\n",
        "        for index in range(class_cnt):\n",
        "            precisions[i].append(contingency_table[index][index] / (np.sum(contingency_table[:, index]) + eps))\n",
        "            recalls[i].append(contingency_table[index][index] / (np.sum(contingency_table[index, :]) + eps))\n",
        "            f1s[i].append(2 * precisions[i][-1] * recalls[i][-1] / ((precisions[i][-1] + recalls[i][-1]) + eps))\n",
        "    precisions = [float(sum(l))/len(l) for l in zip(*precisions)]\n",
        "    recalls = [float(sum(l))/len(l) for l in zip(*recalls)]\n",
        "    f1s = [float(sum(l))/len(l) for l in zip(*f1s)]\n",
        "    print('Accuracy:', round(reduce(lambda x, y: x + y, accuracy) / len(accuracy), 3))\n",
        "    for index in range(class_cnt):\n",
        "        print('_____ Class', index, '_____')\n",
        "        print('Precision\\t', round(precisions[index], 3))\n",
        "        print('Recall\\t\\t', round(recalls[index], 3))\n",
        "        print('F1 Score\\t', round(f1s[index], 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGWVzUPeynbI",
        "colab_type": "code",
        "outputId": "c191a98e-310c-4078-ed0d-59995c67b30e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('Constructing Model ...', end='')\n",
        "\n",
        "model_input = tf.keras.Input((max_seg, max_word))\n",
        "\n",
        "embedding_layer = tf.keras.layers.Embedding(\n",
        "    input_dim=w2v.shape[0], \n",
        "    output_dim=w2v_len, \n",
        "    weights=[w2v], \n",
        "    input_length=max_word, \n",
        "    trainable=False\n",
        ")(model_input)\n",
        "\n",
        "encoding_layer = branch_execute(\n",
        "    embedding_layer, \n",
        "    sublayer=__multi_kernel_encode_layer, \n",
        "    args={\n",
        "        'hidden_feature_dim': 100,\n",
        "        'kernel_heights': [3, 4, 5],\n",
        "        'eta': 1e-4\n",
        "    }\n",
        ")\n",
        "\n",
        "biglu_layer = bidirectional_gru_layer(\n",
        "    encoding_layer, \n",
        "    gru_feature_dim=50\n",
        ")\n",
        "\n",
        "attention_layer = branch_execute(\n",
        "    biglu_layer, \n",
        "    sublayer=__attention_layer_share, \n",
        "    args={\n",
        "        'attention_key_dim': 100,\n",
        "        'dropout_rate': 0.5,\n",
        "        'eta': 1e-4\n",
        "    }\n",
        ")\n",
        "\n",
        "softmaxed_attention_layer = tf.keras.layers.Softmax(\n",
        "    axis=1\n",
        ")(attention_layer)\n",
        "\n",
        "classification_layer = branch_execute(\n",
        "    encoding_layer, \n",
        "    sublayer=__seg_classifier_layer_share, \n",
        "    args={\n",
        "        'class_cnt': level_class_cnt,\n",
        "        'dropout_rate': 0.5,\n",
        "        'eta': 1e-4\n",
        "    }\n",
        ")\n",
        "\n",
        "merge_layer = merge_layer(\n",
        "    [softmaxed_attention_layer, classification_layer],\n",
        "    class_cnt=level_class_cnt,\n",
        "    eta=1e-4\n",
        ")\n",
        "\n",
        "model = tf.keras.Model(model_input, merge_layer)\n",
        "\n",
        "print('\\rModel Constructed. Compiling ...', end='')\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(clipvalue=0.5),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print('\\rModel Compiled.')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0716 21:49:14.589535 139727445047168 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Constructing Model ..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0716 21:49:18.106675 139727445047168 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0716 21:49:19.845074 139727445047168 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0716 21:49:19.846743 139727445047168 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0716 21:49:19.847890 139727445047168 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\rModel Constructed. Compiling ...\rModel Compiled.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 7, 18)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 7, 18, 300)   49505700    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 18, 300)      0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 18, 300)      0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 18, 300)      0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 18, 300)      0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 18, 300)      0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 18, 300)      0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 18, 300)      0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 16, 100)      90100       lambda[0][0]                     \n",
            "                                                                 lambda_1[0][0]                   \n",
            "                                                                 lambda_2[0][0]                   \n",
            "                                                                 lambda_3[0][0]                   \n",
            "                                                                 lambda_4[0][0]                   \n",
            "                                                                 lambda_5[0][0]                   \n",
            "                                                                 lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 15, 100)      120100      lambda[0][0]                     \n",
            "                                                                 lambda_1[0][0]                   \n",
            "                                                                 lambda_2[0][0]                   \n",
            "                                                                 lambda_3[0][0]                   \n",
            "                                                                 lambda_4[0][0]                   \n",
            "                                                                 lambda_5[0][0]                   \n",
            "                                                                 lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 14, 100)      150100      lambda[0][0]                     \n",
            "                                                                 lambda_1[0][0]                   \n",
            "                                                                 lambda_2[0][0]                   \n",
            "                                                                 lambda_3[0][0]                   \n",
            "                                                                 lambda_4[0][0]                   \n",
            "                                                                 lambda_5[0][0]                   \n",
            "                                                                 lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 16, 100)      400         conv1d[0][0]                     \n",
            "                                                                 conv1d[1][0]                     \n",
            "                                                                 conv1d[2][0]                     \n",
            "                                                                 conv1d[3][0]                     \n",
            "                                                                 conv1d[4][0]                     \n",
            "                                                                 conv1d[5][0]                     \n",
            "                                                                 conv1d[6][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 15, 100)      400         conv1d_1[0][0]                   \n",
            "                                                                 conv1d_1[1][0]                   \n",
            "                                                                 conv1d_1[2][0]                   \n",
            "                                                                 conv1d_1[3][0]                   \n",
            "                                                                 conv1d_1[4][0]                   \n",
            "                                                                 conv1d_1[5][0]                   \n",
            "                                                                 conv1d_1[6][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 14, 100)      400         conv1d_2[0][0]                   \n",
            "                                                                 conv1d_2[1][0]                   \n",
            "                                                                 conv1d_2[2][0]                   \n",
            "                                                                 conv1d_2[3][0]                   \n",
            "                                                                 conv1d_2[4][0]                   \n",
            "                                                                 conv1d_2[5][0]                   \n",
            "                                                                 conv1d_2[6][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu (ReLU)                    (None, 16, 100)      0           batch_normalization[0][0]        \n",
            "                                                                 batch_normalization[1][0]        \n",
            "                                                                 batch_normalization[2][0]        \n",
            "                                                                 batch_normalization[3][0]        \n",
            "                                                                 batch_normalization[4][0]        \n",
            "                                                                 batch_normalization[5][0]        \n",
            "                                                                 batch_normalization[6][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_1 (ReLU)                  (None, 15, 100)      0           batch_normalization_1[0][0]      \n",
            "                                                                 batch_normalization_1[1][0]      \n",
            "                                                                 batch_normalization_1[2][0]      \n",
            "                                                                 batch_normalization_1[3][0]      \n",
            "                                                                 batch_normalization_1[4][0]      \n",
            "                                                                 batch_normalization_1[5][0]      \n",
            "                                                                 batch_normalization_1[6][0]      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_2 (ReLU)                  (None, 14, 100)      0           batch_normalization_2[0][0]      \n",
            "                                                                 batch_normalization_2[1][0]      \n",
            "                                                                 batch_normalization_2[2][0]      \n",
            "                                                                 batch_normalization_2[3][0]      \n",
            "                                                                 batch_normalization_2[4][0]      \n",
            "                                                                 batch_normalization_2[5][0]      \n",
            "                                                                 batch_normalization_2[6][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 1, 100)       0           re_lu[0][0]                      \n",
            "                                                                 re_lu[1][0]                      \n",
            "                                                                 re_lu[2][0]                      \n",
            "                                                                 re_lu[3][0]                      \n",
            "                                                                 re_lu[4][0]                      \n",
            "                                                                 re_lu[5][0]                      \n",
            "                                                                 re_lu[6][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 1, 100)       0           re_lu_1[0][0]                    \n",
            "                                                                 re_lu_1[1][0]                    \n",
            "                                                                 re_lu_1[2][0]                    \n",
            "                                                                 re_lu_1[3][0]                    \n",
            "                                                                 re_lu_1[4][0]                    \n",
            "                                                                 re_lu_1[5][0]                    \n",
            "                                                                 re_lu_1[6][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 1, 100)       0           re_lu_2[0][0]                    \n",
            "                                                                 re_lu_2[1][0]                    \n",
            "                                                                 re_lu_2[2][0]                    \n",
            "                                                                 re_lu_2[3][0]                    \n",
            "                                                                 re_lu_2[4][0]                    \n",
            "                                                                 re_lu_2[5][0]                    \n",
            "                                                                 re_lu_2[6][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 1, 300)       0           max_pooling1d[0][0]              \n",
            "                                                                 max_pooling1d_1[0][0]            \n",
            "                                                                 max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1, 300)       0           max_pooling1d[1][0]              \n",
            "                                                                 max_pooling1d_1[1][0]            \n",
            "                                                                 max_pooling1d_2[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 1, 300)       0           max_pooling1d[2][0]              \n",
            "                                                                 max_pooling1d_1[2][0]            \n",
            "                                                                 max_pooling1d_2[2][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 1, 300)       0           max_pooling1d[3][0]              \n",
            "                                                                 max_pooling1d_1[3][0]            \n",
            "                                                                 max_pooling1d_2[3][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 1, 300)       0           max_pooling1d[4][0]              \n",
            "                                                                 max_pooling1d_1[4][0]            \n",
            "                                                                 max_pooling1d_2[4][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 1, 300)       0           max_pooling1d[5][0]              \n",
            "                                                                 max_pooling1d_1[5][0]            \n",
            "                                                                 max_pooling1d_2[5][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 1, 300)       0           max_pooling1d[6][0]              \n",
            "                                                                 max_pooling1d_1[6][0]            \n",
            "                                                                 max_pooling1d_2[6][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 300)          0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 300)          0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 300)          0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 300)          0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 300)          0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 300)          0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 300)          0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_7 (Lambda)               (None, 1, 300)       0           flatten[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "                                                                 flatten_4[0][0]                  \n",
            "                                                                 flatten_5[0][0]                  \n",
            "                                                                 flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 7, 300)       0           lambda_7[0][0]                   \n",
            "                                                                 lambda_7[1][0]                   \n",
            "                                                                 lambda_7[2][0]                   \n",
            "                                                                 lambda_7[3][0]                   \n",
            "                                                                 lambda_7[4][0]                   \n",
            "                                                                 lambda_7[5][0]                   \n",
            "                                                                 lambda_7[6][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 7, 100)       105300      concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, 100)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_9 (Lambda)               (None, 100)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_10 (Lambda)              (None, 100)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_11 (Lambda)              (None, 100)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_12 (Lambda)              (None, 100)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_13 (Lambda)              (None, 100)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_14 (Lambda)              (None, 100)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 100)          0           lambda_8[0][0]                   \n",
            "                                                                 lambda_9[0][0]                   \n",
            "                                                                 lambda_10[0][0]                  \n",
            "                                                                 lambda_11[0][0]                  \n",
            "                                                                 lambda_12[0][0]                  \n",
            "                                                                 lambda_13[0][0]                  \n",
            "                                                                 lambda_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          10100       dropout[0][0]                    \n",
            "                                                                 dropout[1][0]                    \n",
            "                                                                 dropout[2][0]                    \n",
            "                                                                 dropout[3][0]                    \n",
            "                                                                 dropout[4][0]                    \n",
            "                                                                 dropout[5][0]                    \n",
            "                                                                 dropout[6][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_16 (Lambda)              (None, 300)          0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_17 (Lambda)              (None, 300)          0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_18 (Lambda)              (None, 300)          0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_19 (Lambda)              (None, 300)          0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_20 (Lambda)              (None, 300)          0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_21 (Lambda)              (None, 300)          0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_22 (Lambda)              (None, 300)          0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            100         dense[0][0]                      \n",
            "                                                                 dense[1][0]                      \n",
            "                                                                 dense[2][0]                      \n",
            "                                                                 dense[3][0]                      \n",
            "                                                                 dense[4][0]                      \n",
            "                                                                 dense[5][0]                      \n",
            "                                                                 dense[6][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 300)          0           lambda_16[0][0]                  \n",
            "                                                                 lambda_17[0][0]                  \n",
            "                                                                 lambda_18[0][0]                  \n",
            "                                                                 lambda_19[0][0]                  \n",
            "                                                                 lambda_20[0][0]                  \n",
            "                                                                 lambda_21[0][0]                  \n",
            "                                                                 lambda_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_15 (Lambda)              (None, 1, 1)         0           dense_1[0][0]                    \n",
            "                                                                 dense_1[1][0]                    \n",
            "                                                                 dense_1[2][0]                    \n",
            "                                                                 dense_1[3][0]                    \n",
            "                                                                 dense_1[4][0]                    \n",
            "                                                                 dense_1[5][0]                    \n",
            "                                                                 dense_1[6][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 3)            903         dropout_1[0][0]                  \n",
            "                                                                 dropout_1[1][0]                  \n",
            "                                                                 dropout_1[2][0]                  \n",
            "                                                                 dropout_1[3][0]                  \n",
            "                                                                 dropout_1[4][0]                  \n",
            "                                                                 dropout_1[5][0]                  \n",
            "                                                                 dropout_1[6][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 7, 1)         0           lambda_15[0][0]                  \n",
            "                                                                 lambda_15[1][0]                  \n",
            "                                                                 lambda_15[2][0]                  \n",
            "                                                                 lambda_15[3][0]                  \n",
            "                                                                 lambda_15[4][0]                  \n",
            "                                                                 lambda_15[5][0]                  \n",
            "                                                                 lambda_15[6][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_23 (Lambda)              (None, 1, 3)         0           dense_2[0][0]                    \n",
            "                                                                 dense_2[1][0]                    \n",
            "                                                                 dense_2[2][0]                    \n",
            "                                                                 dense_2[3][0]                    \n",
            "                                                                 dense_2[4][0]                    \n",
            "                                                                 dense_2[5][0]                    \n",
            "                                                                 dense_2[6][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Softmax)               (None, 7, 1)         0           concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 7, 3)         0           lambda_23[0][0]                  \n",
            "                                                                 lambda_23[1][0]                  \n",
            "                                                                 lambda_23[2][0]                  \n",
            "                                                                 lambda_23[3][0]                  \n",
            "                                                                 lambda_23[4][0]                  \n",
            "                                                                 lambda_23[5][0]                  \n",
            "                                                                 lambda_23[6][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 1, 3)         0           softmax[0][0]                    \n",
            "                                                                 concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_7 (Flatten)             (None, 3)            0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 3)            12          flatten_7[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 49,983,615\n",
            "Trainable params: 477,315\n",
            "Non-trainable params: 49,506,300\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8n0VXyiyrDU",
        "colab_type": "code",
        "outputId": "8bf8c2c8-9bca-4566-d5e7-773ed9e93ad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "logdir = os.path.join(log_out_dir, datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=0)\n",
        "\n",
        "model.fit_generator(\n",
        "    data_generator(train_batches, use_balance=True), \n",
        "    validation_data=data_generator(validation_batches, use_balance=True),\n",
        "    steps_per_epoch=(sample_amount * (1 - test_percentage - validation_percentage) // batch_size) - 1,\n",
        "    validation_steps=(sample_amount * (validation_percentage) // batch_size) - 1,\n",
        "    validation_freq=2,\n",
        "    epochs=epochs,\n",
        "    callbacks=[tensorboard_callback],\n",
        ")\n",
        "\n",
        "model.save(model_out_path)\n",
        "\n",
        "print('########## Training Error ##########')\n",
        "performance_judge(model, data_generator(train_batches, epochs=1, use_balance=True), level_class_cnt)\n",
        "print('')\n",
        "print('############ Test Error ############')\n",
        "performance_judge(model, data_generator(test_batches, epochs=1, use_balance=True), level_class_cnt)\n",
        "\n",
        "print(logdir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0716 21:49:34.033973 139727445047168 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "451/451 [==============================] - 133s 295ms/step - loss: 0.9659 - acc: 0.6136\n",
            "Epoch 2/8\n",
            "451/451 [==============================] - 105s 233ms/step - loss: 0.8101 - acc: 0.7009 - val_loss: 0.7419 - val_acc: 0.7328\n",
            "Epoch 3/8\n",
            "451/451 [==============================] - 98s 217ms/step - loss: 0.7350 - acc: 0.7293\n",
            "Epoch 4/8\n",
            "451/451 [==============================] - 101s 224ms/step - loss: 0.6915 - acc: 0.7454 - val_loss: 0.6841 - val_acc: 0.7460\n",
            "Epoch 5/8\n",
            "451/451 [==============================] - 91s 203ms/step - loss: 0.6584 - acc: 0.7605\n",
            "Epoch 6/8\n",
            "451/451 [==============================] - 98s 218ms/step - loss: 0.6361 - acc: 0.7711 - val_loss: 0.6520 - val_acc: 0.7643\n",
            "Epoch 7/8\n",
            "451/451 [==============================] - 92s 203ms/step - loss: 0.6163 - acc: 0.7813\n",
            "Epoch 8/8\n",
            "451/451 [==============================] - 97s 215ms/step - loss: 0.5969 - acc: 0.7911 - val_loss: 0.6562 - val_acc: 0.7704\n",
            "########## Training Error ##########\n",
            "Accuracy: 0.82\n",
            "_____ Class 0 _____\n",
            "Precision\t 0.811\n",
            "Recall\t\t 0.742\n",
            "F1 Score\t 0.774\n",
            "_____ Class 1 _____\n",
            "Precision\t 0.821\n",
            "Recall\t\t 0.777\n",
            "F1 Score\t 0.798\n",
            "_____ Class 2 _____\n",
            "Precision\t 0.827\n",
            "Recall\t\t 0.93\n",
            "F1 Score\t 0.875\n",
            "\n",
            "############ Test Error ############\n",
            "Accuracy: 0.77\n",
            "_____ Class 0 _____\n",
            "Precision\t 0.75\n",
            "Recall\t\t 0.678\n",
            "F1 Score\t 0.711\n",
            "_____ Class 1 _____\n",
            "Precision\t 0.776\n",
            "Recall\t\t 0.73\n",
            "F1 Score\t 0.752\n",
            "_____ Class 2 _____\n",
            "Precision\t 0.777\n",
            "Recall\t\t 0.886\n",
            "F1 Score\t 0.827\n",
            "/content/gdrive/My Drive/data_source/milnet/log/20190716_214930\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEgo5rrl6Nmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}